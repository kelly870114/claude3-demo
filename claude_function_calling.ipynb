{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e31241a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3==1.34.131\n",
      "  Downloading boto3-1.34.131-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting botocore<1.35.0,>=1.34.131 (from boto3==1.34.131)\n",
      "  Downloading botocore-1.34.136-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3==1.34.131) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from boto3==1.34.131) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.131->boto3==1.34.131) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.131->boto3==1.34.131) (1.26.18)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.131->boto3==1.34.131) (1.16.0)\n",
      "Downloading boto3-1.34.131-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.34.136-py3-none-any.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m114.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: botocore, boto3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.34.51\n",
      "    Uninstalling botocore-1.34.51:\n",
      "      Successfully uninstalled botocore-1.34.51\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.34.51\n",
      "    Uninstalling boto3-1.34.51:\n",
      "      Successfully uninstalled boto3-1.34.51\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.12.2 requires botocore<1.34.52,>=1.34.41, but you have botocore 1.34.136 which is incompatible.\n",
      "autogluon-common 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-core 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-core 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-features 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-features 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires pytorch-lightning<1.10.0,>=1.9.0, but you have pytorch-lightning 2.0.9 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires torch<1.14,>=1.9, but you have torch 2.0.0.post104 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires torchmetrics<0.12.0,>=0.11.0, but you have torchmetrics 1.0.3 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires torchvision<0.15.0, but you have torchvision 0.15.2a0+ab7b3e6 which is incompatible.\n",
      "autogluon-tabular 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-tabular 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-timeseries 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-timeseries 0.8.3 requires pytorch-lightning<1.10.0,>=1.7.4, but you have pytorch-lightning 2.0.9 which is incompatible.\n",
      "autogluon-timeseries 0.8.3 requires torch<1.14,>=1.9, but you have torch 2.0.0.post104 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed boto3-1.34.131 botocore-1.34.136\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3=='1.34.131'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4206c35f-ad16-49e5-bc3c-b1235b14447d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Streaming messages with model anthropic.claude-3-haiku-20240307-v1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's find the most popular song on the radio station WZPZ."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Streaming messages with model anthropic.claude-3-haiku-20240307-v1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most popular song currently playing on radio station WZPZ is \"Elemental Hotel\" by the artist 8 Storey Hike.\n",
      "Finished streaming messages with model anthropic.claude-3-haiku-20240307-v1:0.\n"
     ]
    }
   ],
   "source": [
    "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "# AWS Document 範例\n",
    "\"\"\"\n",
    "Shows how to use a tool with a streaming conversation.\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "class StationNotFoundError(Exception):\n",
    "    \"\"\"Raised when a radio station isn't found.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_top_song(call_sign):\n",
    "    \"\"\"Returns the most popular song for the requested station.\n",
    "    Args:\n",
    "        call_sign (str): The call sign for the station for which you want\n",
    "        the most popular song.\n",
    "\n",
    "    Returns:\n",
    "        response (json): The most popular song and artist.\n",
    "    \"\"\"\n",
    "\n",
    "    song = \"\"\n",
    "    artist = \"\"\n",
    "    if call_sign == 'WZPZ':\n",
    "        song = \"Elemental Hotel\"\n",
    "        artist = \"8 Storey Hike\"\n",
    "\n",
    "    else:\n",
    "        raise StationNotFoundError(f\"Station {call_sign} not found.\")\n",
    "\n",
    "    return song, artist\n",
    "\n",
    "\n",
    "def stream_messages(bedrock_client,\n",
    "                    model_id,\n",
    "                    messages,\n",
    "                    tool_config):\n",
    "    \"\"\"\n",
    "    Sends a message to a model and streams the response.\n",
    "    Args:\n",
    "        bedrock_client: The Boto3 Bedrock runtime client.\n",
    "        model_id (str): The model ID to use.\n",
    "        messages (JSON) : The messages to send to the model.\n",
    "        tool_config : Tool Information to send to the model.\n",
    "\n",
    "    Returns:\n",
    "        stop_reason (str): The reason why the model stopped generating text.\n",
    "        message (JSON): The message that the model generated.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    logger.info(\"Streaming messages with model %s\", model_id)\n",
    "\n",
    "    response = bedrock_client.converse_stream(\n",
    "        modelId=model_id,\n",
    "        messages=messages,\n",
    "        toolConfig=tool_config\n",
    "    )\n",
    "\n",
    "    stop_reason = \"\"\n",
    " \n",
    "    message = {}\n",
    "    content = []\n",
    "    message['content'] = content\n",
    "    text = ''\n",
    "    tool_use = {}\n",
    "\n",
    "\n",
    "    #stream the response into a message.\n",
    "    for chunk in response['stream']:\n",
    "        if 'messageStart' in chunk:\n",
    "            message['role'] = chunk['messageStart']['role']\n",
    "        elif 'contentBlockStart' in chunk:\n",
    "            tool = chunk['contentBlockStart']['start']['toolUse']\n",
    "            tool_use['toolUseId'] = tool['toolUseId']\n",
    "            tool_use['name'] = tool['name']\n",
    "        elif 'contentBlockDelta' in chunk:\n",
    "            delta = chunk['contentBlockDelta']['delta']\n",
    "            if 'toolUse' in delta:\n",
    "                if 'input' not in tool_use:\n",
    "                    tool_use['input'] = ''\n",
    "                tool_use['input'] += delta['toolUse']['input']\n",
    "            elif 'text' in delta:\n",
    "                text += delta['text']\n",
    "                print(delta['text'], end='')\n",
    "        elif 'contentBlockStop' in chunk:\n",
    "            if 'input' in tool_use:\n",
    "                tool_use['input'] = json.loads(tool_use['input'])\n",
    "                content.append({'toolUse': tool_use})\n",
    "                tool_use = {}\n",
    "            else:\n",
    "                content.append({'text': text})\n",
    "                text = ''\n",
    "\n",
    "        elif 'messageStop' in chunk:\n",
    "            stop_reason = chunk['messageStop']['stopReason']\n",
    "\n",
    "    return stop_reason, message\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Entrypoint for streaming tool use example.\n",
    "    \"\"\"\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO,\n",
    "                        format=\"%(levelname)s: %(message)s\")\n",
    "\n",
    "    model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "    input_text = \"What is the most popular song on WZPZ?\"\n",
    "\n",
    "    try:\n",
    "        bedrock_client = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "        # Create the initial message from the user input.\n",
    "        messages = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"text\": input_text}]\n",
    "        }]\n",
    "\n",
    "        # Define the tool to send to the model.\n",
    "        tool_config = {\n",
    "            \"tools\": [\n",
    "                {\n",
    "                    \"toolSpec\": {\n",
    "                        \"name\": \"top_song\",\n",
    "                        \"description\": \"Get the most popular song played on a radio station.\",\n",
    "                        \"inputSchema\": {\n",
    "                            \"json\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"sign\": {\n",
    "                                        \"type\": \"string\",\n",
    "                                        \"description\": \"The call sign for the radio station for which you want the most popular song. Example calls signs are WZPZ and WKRP.\"\n",
    "                                    }\n",
    "                                },\n",
    "                                \"required\": [\"sign\"]\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "\n",
    "        # Send the message and get the tool use request from response.\n",
    "        stop_reason, message = stream_messages(\n",
    "            bedrock_client, model_id, messages, tool_config)\n",
    "        messages.append(message)\n",
    "\n",
    "        if stop_reason == \"tool_use\":\n",
    "\n",
    "            for content in message['content']:\n",
    "                if 'toolUse' in content:\n",
    "                    tool = content['toolUse']\n",
    "\n",
    "                    if tool['name'] == 'top_song':\n",
    "                        tool_result = {}\n",
    "                        try:\n",
    "                            song, artist = get_top_song(tool['input']['sign'])\n",
    "                            tool_result = {\n",
    "                                \"toolUseId\": tool['toolUseId'],\n",
    "                                \"content\": [{\"json\": {\"song\": song, \"artist\": artist}}]\n",
    "                            }\n",
    "                        except StationNotFoundError as err:\n",
    "                            tool_result = {\n",
    "                                \"toolUseId\": tool['toolUseId'],\n",
    "                                \"content\": [{\"text\":  err.args[0]}],\n",
    "                                \"status\": 'error'\n",
    "                            }\n",
    "\n",
    "                        tool_result_message = {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [\n",
    "                                {\n",
    "                                    \"toolResult\": tool_result\n",
    "\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                        # Add the result info to message. \n",
    "                        messages.append(tool_result_message)\n",
    "\n",
    "        #Send the messages, including the tool result, to the model.\n",
    "        stop_reason, message  = stream_messages(\n",
    "            bedrock_client, model_id, messages, tool_config)\n",
    "\n",
    "\n",
    "    except ClientError as err:\n",
    "        message = err.response['Error']['Message']\n",
    "        logger.error(\"A client error occurred: %s\", message)\n",
    "        print(\"A client error occured: \" +\n",
    "              format(message))\n",
    "\n",
    "    else:\n",
    "        print(\n",
    "            f\"\\nFinished streaming messages with model {model_id}.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dd99252-c6dd-4bc3-a0a1-4e8ec2fc2cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Streaming messages with model anthropic.claude-3-haiku-20240307-v1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the HTML and JavaScript code for a simple Tetris game that can be uploaded to an S3 bucket:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Streaming messages with model anthropic.claude-3-haiku-20240307-v1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The HTML file includes a canvas element where the Tetris game will be rendered, and a \"Start\" button to begin the game. The JavaScript code handles the game logic, including the game loop, updating the game state, and drawing the game on the canvas.\n",
      "\n",
      "After creating the HTML file, I have uploaded it to an S3 bucket named \"ginny-claude3-website\" using the `upload_to_s3` function. The file is named \"index.html\".\n",
      "Final response: The HTML file includes a canvas element where the Tetris game will be rendered, and a \"Start\" button to begin the game. The JavaScript code handles the game logic, including the game loop, updating the game state, and drawing the game on the canvas.\n",
      "\n",
      "After creating the HTML file, I have uploaded it to an S3 bucket named \"ginny-claude3-website\" using the `upload_to_s3` function. The file is named \"index.html\".\n"
     ]
    }
   ],
   "source": [
    "# Tell LLM to upload html file to s3 and make it a website\n",
    "\n",
    "import logging\n",
    "import json\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "BUCKET_NAME = \"ginny-claude3-website\"  # 替換為您的 S3 桶名\n",
    "\n",
    "class UploadError(Exception):\n",
    "    \"\"\"上傳到 S3 失敗。\"\"\"\n",
    "    pass\n",
    "\n",
    "def upload_to_s3(file_content, file_name):\n",
    "    \"\"\"\n",
    "    將內容上傳到 S3，並設置 content_type 為 'text/html'\n",
    "\n",
    "    Args:\n",
    "        file_content (str): 要上傳的文件內容。\n",
    "        file_name (str): 在 S3 中的文件名。\n",
    "\n",
    "    Returns:\n",
    "        str: 上傳成功\n",
    "        or UploadError: 上傳失敗。\n",
    "    \"\"\"\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    try:\n",
    "        with tempfile.NamedTemporaryFile(mode='w', delete=False) as temp_file:\n",
    "            temp_file.write(file_content)\n",
    "            temp_file_path = temp_file.name\n",
    "\n",
    "        # 使用 put_object 而不是 upload_file，以便我們可以設置 ContentType\n",
    "        with open(temp_file_path, 'rb') as file:\n",
    "            s3_client.put_object(\n",
    "                Bucket=BUCKET_NAME,\n",
    "                Key=file_name,\n",
    "                Body=file,\n",
    "                ContentType='text/html'  # 設置 content_type 為 'text/html'\n",
    "            )\n",
    "\n",
    "        os.unlink(temp_file_path)\n",
    "        return f\"File {file_name} successfully uploaded to S3 bucket {BUCKET_NAME} with content type 'text/html'\"\n",
    "    except Exception as e:\n",
    "        raise UploadError(f\"Failed to upload file to S3: {str(e)}\")\n",
    "\n",
    "def stream_messages(bedrock_client, model_id, messages, tool_config):\n",
    "    \"\"\"\n",
    "    發送消息到model並利用streaming response。\n",
    "\n",
    "    Args:\n",
    "        bedrock_client: Boto3 Bedrock runtime 客戶端。\n",
    "        model_id (str): 要使用的 model ID\n",
    "        messages (JSON): 要發送給模型的 message\n",
    "        tool_config: 要發送給模型的 tool information\n",
    "\n",
    "    Returns:\n",
    "        stop_reason (str): 模型停止生成文本的原因。\n",
    "        message (JSON): 模型生成的消息。\n",
    "    \"\"\"\n",
    "    logger.info(\"Streaming messages with model %s\", model_id)\n",
    "\n",
    "    response = bedrock_client.converse_stream(\n",
    "        modelId=model_id,\n",
    "        messages=messages,\n",
    "        toolConfig=tool_config\n",
    "    )\n",
    "\n",
    "    stop_reason = \"\"\n",
    "    message = {}\n",
    "    content = []\n",
    "    message['content'] = content\n",
    "    text = ''\n",
    "    tool_use = {}\n",
    "\n",
    "    for chunk in response['stream']:\n",
    "        if 'messageStart' in chunk:\n",
    "            message['role'] = chunk['messageStart']['role']\n",
    "        elif 'contentBlockStart' in chunk:\n",
    "            tool = chunk['contentBlockStart']['start']['toolUse']\n",
    "            tool_use['toolUseId'] = tool['toolUseId']\n",
    "            tool_use['name'] = tool['name']\n",
    "        elif 'contentBlockDelta' in chunk:\n",
    "            delta = chunk['contentBlockDelta']['delta']\n",
    "            if 'toolUse' in delta:\n",
    "                if 'input' not in tool_use:\n",
    "                    tool_use['input'] = ''\n",
    "                tool_use['input'] += delta['toolUse']['input']\n",
    "            elif 'text' in delta:\n",
    "                text += delta['text']\n",
    "                print(delta['text'], end='')\n",
    "        elif 'contentBlockStop' in chunk:\n",
    "            if 'input' in tool_use:\n",
    "                tool_use['input'] = json.loads(tool_use['input'])\n",
    "                content.append({'toolUse': tool_use})\n",
    "                tool_use = {}\n",
    "            else:\n",
    "                content.append({'text': text})\n",
    "                text = ''\n",
    "        elif 'messageStop' in chunk:\n",
    "            stop_reason = chunk['messageStop']['stopReason']\n",
    "\n",
    "    return stop_reason, message\n",
    "\n",
    "def chat(user_input):\n",
    "    \"\"\"\n",
    "    處理用戶輸入並生成回應。\n",
    "\n",
    "    Args:\n",
    "        user_input (str): 用戶的輸入文本。\n",
    "\n",
    "    Returns:\n",
    "        str: 模型的最終回應。\n",
    "    \"\"\"\n",
    "    model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "\n",
    "    try:\n",
    "        bedrock_client = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "        messages = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"text\": user_input}]\n",
    "        }]\n",
    "\n",
    "        tool_config = {\n",
    "            \"tools\": [\n",
    "                {\n",
    "                    \"toolSpec\": {\n",
    "                        \"name\": \"upload_to_s3\",\n",
    "                        \"description\": \"Upload content to an S3 bucket as an HTML file.\",\n",
    "                        \"inputSchema\": {\n",
    "                            \"json\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"file_content\": {\n",
    "                                        \"type\": \"string\",\n",
    "                                        \"description\": \"The HTML content to be uploaded to S3.\"\n",
    "                                    },\n",
    "                                    \"file_name\": {\n",
    "                                        \"type\": \"string\",\n",
    "                                        \"description\": \"The name of the HTML file in S3.\"\n",
    "                                    }\n",
    "                                },\n",
    "                                \"required\": [\"file_content\", \"file_name\"]\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        stop_reason, message = stream_messages(\n",
    "            bedrock_client, model_id, messages, tool_config)\n",
    "        messages.append(message)\n",
    "\n",
    "        if stop_reason == \"tool_use\":\n",
    "            for content in message['content']:\n",
    "                if 'toolUse' in content:\n",
    "                    tool = content['toolUse']\n",
    "\n",
    "                    if tool['name'] == 'upload_to_s3':\n",
    "                        tool_result = {}\n",
    "                        try:\n",
    "                            result = upload_to_s3(tool['input']['file_content'], tool['input']['file_name'])\n",
    "                            tool_result = {\n",
    "                                \"toolUseId\": tool['toolUseId'],\n",
    "                                \"content\": [{\"text\": result}]\n",
    "                            }\n",
    "                        except UploadError as err:\n",
    "                            tool_result = {\n",
    "                                \"toolUseId\": tool['toolUseId'],\n",
    "                                \"content\": [{\"text\": err.args[0]}],\n",
    "                                \"status\": 'error'\n",
    "                            }\n",
    "\n",
    "                        tool_result_message = {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [\n",
    "                                {\n",
    "                                    \"toolResult\": tool_result\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                        messages.append(tool_result_message)\n",
    "\n",
    "        stop_reason, final_message = stream_messages(\n",
    "            bedrock_client, model_id, messages, tool_config)\n",
    "\n",
    "        return final_message['content'][0]['text']\n",
    "\n",
    "    except ClientError as err:\n",
    "        message = err.response['Error']['Message']\n",
    "        logger.error(\"A client error occurred: %s\", message)\n",
    "        return f\"An error occurred: {message}\"\n",
    "\n",
    "# 範例\n",
    "if __name__ == \"__main__\":\n",
    "    user_input = \"Can you create a tetris game using html and Javascript in a html file, we need a start button to start the game. Once you create the html file, name it 'index.html' and upload it to S3\"\n",
    "    response = chat(user_input)\n",
    "    print(\"\\nFinal response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7643c5-fc00-4bc5-a022-747c46f66b58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e0344b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Streaming messages with model anthropic.claude-3-haiku-20240307-v1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the HTML and JavaScript code for a simple Tetris game that can be uploaded to an S3 bucket:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Streaming messages with model anthropic.claude-3-haiku-20240307-v1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The HTML file includes a canvas element where the Tetris game will be rendered, and a \"Start\" button to begin the game. The JavaScript code handles the game logic, including the game loop, updating the game state, and drawing the game on the canvas.\n",
      "\n",
      "After creating the HTML file, I have uploaded it to an S3 bucket named \"ginny-claude3-website\" using the `upload_to_s3` function. The file is named \"index.html\".\n",
      "Final response: The HTML file includes a canvas element where the Tetris game will be rendered, and a \"Start\" button to begin the game. The JavaScript code handles the game logic, including the game loop, updating the game state, and drawing the game on the canvas.\n",
      "\n",
      "After creating the HTML file, I have uploaded it to an S3 bucket named \"ginny-claude3-website\" using the `upload_to_s3` function. The file is named \"index.html\".\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import json\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "BUCKET_NAME = \"ginny-claude3-website\"  # 替換為您的 S3 桶名\n",
    "\n",
    "class UploadError(Exception):\n",
    "    \"\"\"當上傳到 S3 失敗時引發。\"\"\"\n",
    "    pass\n",
    "\n",
    "def upload_to_s3(file_content, file_name):\n",
    "    \"\"\"\n",
    "    將內容上傳到 S3 桶，並設置 content_type 為 'text/html'。\n",
    "\n",
    "    Args:\n",
    "        file_content (str): 要上傳的文件內容。\n",
    "        file_name (str): 在 S3 中的文件名。\n",
    "\n",
    "    Returns:\n",
    "        str: 上傳成功的消息。\n",
    "\n",
    "    Raises:\n",
    "        UploadError: 如果上傳失敗。\n",
    "    \"\"\"\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    try:\n",
    "        with tempfile.NamedTemporaryFile(mode='w', delete=False) as temp_file:\n",
    "            temp_file.write(file_content)\n",
    "            temp_file_path = temp_file.name\n",
    "\n",
    "        # 使用 put_object 而不是 upload_file，以便我們可以設置 ContentType\n",
    "        with open(temp_file_path, 'rb') as file:\n",
    "            s3_client.put_object(\n",
    "                Bucket=BUCKET_NAME,\n",
    "                Key=file_name,\n",
    "                Body=file,\n",
    "                ContentType='text/html'  # 設置 content_type 為 'text/html'\n",
    "            )\n",
    "\n",
    "        os.unlink(temp_file_path)\n",
    "        return f\"File {file_name} successfully uploaded to S3 bucket {BUCKET_NAME} with content type 'text/html'\"\n",
    "    except Exception as e:\n",
    "        raise UploadError(f\"Failed to upload file to S3: {str(e)}\")\n",
    "\n",
    "def stream_messages(bedrock_client, model_id, messages, tool_config):\n",
    "    \"\"\"\n",
    "    發送消息到模型並流式傳輸響應。\n",
    "\n",
    "    Args:\n",
    "        bedrock_client: Boto3 Bedrock runtime 客戶端。\n",
    "        model_id (str): 要使用的模型 ID。\n",
    "        messages (JSON): 要發送給模型的消息。\n",
    "        tool_config: 要發送給模型的工具信息。\n",
    "\n",
    "    Returns:\n",
    "        stop_reason (str): 模型停止生成文本的原因。\n",
    "        message (JSON): 模型生成的消息。\n",
    "    \"\"\"\n",
    "    logger.info(\"Streaming messages with model %s\", model_id)\n",
    "\n",
    "    response = bedrock_client.converse_stream(\n",
    "        modelId=model_id,\n",
    "        messages=messages,\n",
    "        toolConfig=tool_config\n",
    "    )\n",
    "\n",
    "    stop_reason = \"\"\n",
    "    message = {}\n",
    "    content = []\n",
    "    message['content'] = content\n",
    "    text = ''\n",
    "    tool_use = {}\n",
    "\n",
    "    for chunk in response['stream']:\n",
    "        if 'messageStart' in chunk:\n",
    "            message['role'] = chunk['messageStart']['role']\n",
    "        elif 'contentBlockStart' in chunk:\n",
    "            tool = chunk['contentBlockStart']['start']['toolUse']\n",
    "            tool_use['toolUseId'] = tool['toolUseId']\n",
    "            tool_use['name'] = tool['name']\n",
    "        elif 'contentBlockDelta' in chunk:\n",
    "            delta = chunk['contentBlockDelta']['delta']\n",
    "            if 'toolUse' in delta:\n",
    "                if 'input' not in tool_use:\n",
    "                    tool_use['input'] = ''\n",
    "                tool_use['input'] += delta['toolUse']['input']\n",
    "            elif 'text' in delta:\n",
    "                text += delta['text']\n",
    "                print(delta['text'], end='')\n",
    "        elif 'contentBlockStop' in chunk:\n",
    "            if 'input' in tool_use:\n",
    "                tool_use['input'] = json.loads(tool_use['input'])\n",
    "                content.append({'toolUse': tool_use})\n",
    "                tool_use = {}\n",
    "            else:\n",
    "                content.append({'text': text})\n",
    "                text = ''\n",
    "        elif 'messageStop' in chunk:\n",
    "            stop_reason = chunk['messageStop']['stopReason']\n",
    "\n",
    "    return stop_reason, message\n",
    "\n",
    "def chat(user_input):\n",
    "    \"\"\"\n",
    "    處理用戶輸入並生成回應。\n",
    "\n",
    "    Args:\n",
    "        user_input (str): 用戶的輸入文本。\n",
    "\n",
    "    Returns:\n",
    "        str: 模型的最終回應。\n",
    "    \"\"\"\n",
    "    model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "\n",
    "    try:\n",
    "        bedrock_client = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "        messages = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"text\": user_input}]\n",
    "        }]\n",
    "\n",
    "        tool_config = {\n",
    "            \"tools\": [\n",
    "                {\n",
    "                    \"toolSpec\": {\n",
    "                        \"name\": \"upload_to_s3\",\n",
    "                        \"description\": \"Upload content to an S3 bucket as an HTML file.\",\n",
    "                        \"inputSchema\": {\n",
    "                            \"json\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"file_content\": {\n",
    "                                        \"type\": \"string\",\n",
    "                                        \"description\": \"The HTML content to be uploaded to S3.\"\n",
    "                                    },\n",
    "                                    \"file_name\": {\n",
    "                                        \"type\": \"string\",\n",
    "                                        \"description\": \"The name of the HTML file in S3.\"\n",
    "                                    }\n",
    "                                },\n",
    "                                \"required\": [\"file_content\", \"file_name\"]\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        stop_reason, message = stream_messages(\n",
    "            bedrock_client, model_id, messages, tool_config)\n",
    "        messages.append(message)\n",
    "\n",
    "        if stop_reason == \"tool_use\":\n",
    "            for content in message['content']:\n",
    "                if 'toolUse' in content:\n",
    "                    tool = content['toolUse']\n",
    "\n",
    "                    if tool['name'] == 'upload_to_s3':\n",
    "                        tool_result = {}\n",
    "                        try:\n",
    "                            result = upload_to_s3(tool['input']['file_content'], tool['input']['file_name'])\n",
    "                            tool_result = {\n",
    "                                \"toolUseId\": tool['toolUseId'],\n",
    "                                \"content\": [{\"text\": result}]\n",
    "                            }\n",
    "                        except UploadError as err:\n",
    "                            tool_result = {\n",
    "                                \"toolUseId\": tool['toolUseId'],\n",
    "                                \"content\": [{\"text\": err.args[0]}],\n",
    "                                \"status\": 'error'\n",
    "                            }\n",
    "\n",
    "                        tool_result_message = {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [\n",
    "                                {\n",
    "                                    \"toolResult\": tool_result\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                        messages.append(tool_result_message)\n",
    "\n",
    "        stop_reason, final_message = stream_messages(\n",
    "            bedrock_client, model_id, messages, tool_config)\n",
    "\n",
    "        return final_message['content'][0]['text']\n",
    "\n",
    "    except ClientError as err:\n",
    "        message = err.response['Error']['Message']\n",
    "        logger.error(\"A client error occurred: %s\", message)\n",
    "        return f\"An error occurred: {message}\"\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    user_input = \"Can you create a tetris game using html and Javascript in a html file, we need a start button to start the game. Once you create the html file, name it 'index.html' and upload it to S3\"\n",
    "    response = chat(user_input)\n",
    "    print(\"\\nFinal response:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
